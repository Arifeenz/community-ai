const express = require("express");
const bodyParser = require("body-parser");
const cors = require("cors");
const dotenv = require("dotenv");
const { OpenAI } = require("openai");

dotenv.config();

const app = express();
app.use(cors());
app.use(bodyParser.json());

// âœ… à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² KEY à¸–à¸¹à¸à¹‚à¸«à¸¥à¸”à¸ˆà¸£à¸´à¸‡
if (!process.env.OPENAI_API_KEY) {
  console.error("âŒ OPENAI_API_KEY not found in environment variables");
}

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post("/generate", async (req, res) => {
  try {
    const prompt = req.body.prompt;

    if (!prompt) {
      console.error("âŒ Missing prompt");
      return res.status(400).json({ error: "Missing prompt" });
    }

    console.log("ðŸ“© Prompt received:", prompt);

    const completion = await openai.chat.completions.create({
      model: "gpt-4o", // à¸«à¸£à¸·à¸­ gpt-3.5-turbo
      messages: [
        {
          role: "system",
          content:
            "à¸„à¸¸à¸“à¸„à¸·à¸­à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸—à¸µà¹ˆà¸Šà¹ˆà¸§à¸¢à¹€à¸‚à¸µà¸¢à¸™à¹‚à¸žà¸ªà¸•à¹Œà¹à¸™à¸°à¸™à¸³à¸à¸´à¸ˆà¸à¸£à¸£à¸¡à¸‚à¸­à¸‡à¸Šà¸¸à¸¡à¸Šà¸™à¹ƒà¸«à¹‰à¸”à¸¹à¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆà¹à¸¥à¸°à¹€à¸›à¹‡à¸™à¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´",
        },
        { role: "user", content: prompt },
      ],
      temperature: 0.7,
    });

    const aiContent = completion.choices[0].message.content.trim();
    res.json({ content: aiContent });
  } catch (err) {
    console.error("âŒ AI Error:", err);
    res.status(500).json({ error: err.message || "AI Error" });
  }
});

// âœ… Only start server if running locally (Vercel à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ app.listen)
if (process.env.NODE_ENV !== "production") {
  app.listen(3001, () => {
    console.log("âœ… Backend is running at http://localhost:3001");
  });
}

// âœ… Export handler à¸ªà¸³à¸«à¸£à¸±à¸š Vercel
module.exports = app;
